{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Scorecard OpenLLMetry OpenAI Example\n",
        "\n",
        "This notebook demonstrates how to use OpenLLMetry with OpenAI in Python to trace LLM calls and workflows in Scorecard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install traceloop-sdk openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TRACELOOP_BASE_URL=\"https://telemetry.getscorecard.ai:4318\" # Scorecard telemetry url\n",
        "TRACELOOP_HEADERS=\"Authorization=Bearer <YOUR_SCORECARD_TELEMETRY_KEY>\"\n",
        "\n",
        "OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from traceloop.sdk import Traceloop\n",
        "from traceloop.sdk.decorators import workflow, task\n",
        "from traceloop.sdk.instruments import Instruments\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Initialize Traceloop\n",
        "Traceloop.init(disable_batch=True, instruments={Instruments.OPENAI})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@task(name=\"joke_creation\")\n",
        "def create_joke():\n",
        "    \"\"\"Create a joke using OpenAI\"\"\"\n",
        "    completion = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Tell me a joke\"}]\n",
        "    )\n",
        "    \n",
        "    return completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@task(name=\"author_generation\")\n",
        "def generate_author(joke: str):\n",
        "    \"\"\"Generate an author for the given joke\"\"\"\n",
        "    completion = openai_client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"add a author to the joke:\\n\\n{joke}\"}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@workflow(name=\"joke_generator\")\n",
        "def joke_workflow():\n",
        "    \"\"\"Main workflow that creates a joke and generates an author for it\"\"\"\n",
        "    joke = create_joke()\n",
        "    print(f\"Generated joke: {joke}\")\n",
        "    \n",
        "    joke_with_author = generate_author(joke)\n",
        "    print(f\"Joke with author: {joke_with_author}\")\n",
        "    \n",
        "    return joke_with_author\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the workflow\n",
        "result = joke_workflow()\n",
        "print(\"\\nWorkflow completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Viewing Traces in Scorecard\n",
        "\n",
        "After running your application:\n",
        "\n",
        "1. **Visit Scorecard**: Go to [app.getscorecard.ai](https://app.getscorecard.ai)\n",
        "2. **Navigate to Traces**: Go to your project â†’ Traces section\n",
        "\n",
        "### What You'll See\n",
        "\n",
        "- **Workflow spans**: High-level operations (`joke_generator`)\n",
        "- **Task spans**: Individual operations (`joke_creation`, `author_generation`)  \n",
        "- **LLM spans**: Automatic OpenAI API call instrumentation\n",
        "- **Timing data**: Duration of each operation\n",
        "- **Token usage**: Input/output tokens for LLM calls\n",
        "- **Model information**: Which models were used\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
